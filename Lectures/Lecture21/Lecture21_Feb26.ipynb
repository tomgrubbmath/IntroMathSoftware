{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lecture 21: Word Embeddings\n",
    "\n",
    "### Please note: This lecture will be recorded and made available for viewing online. If you do not wish to be recorded, please adjust your camera settings accordingly. \n",
    "\n",
    "# Reminders/Announcements:\n",
    "- Assignment 7 has been collected. One homework assignment left!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Last Time: Stylometry\n",
    "\n",
    "We studied *how individuals use language*, and how that changes between different individuals. In particular, we studied things like \n",
    "- Distribution of sentence lengths\n",
    "- Distribution of word lengths\n",
    "- Distribution of word rates\n",
    "\n",
    "In particular, we introduced the idea of a *classifier*: given a bunch of numeric data, predict a *category* that a data point belongs to. Since we rushed through it a bit, I just want to give an overview to contextualize it a bit more. \n",
    "\n",
    "We had \n",
    "- 51 papers which were *definitely written by Hamilton* (First category!)\n",
    "- 15 papers which were *definitely written by Madison* (Second category!)\n",
    "- 11 papers which were written by *Hamilton or Madison* (Unknown category!)\n",
    "\n",
    "What did we do? We chose a list of *marker words*: on, upon, while, whilst, ... and noticed that different words were used with different frequencies when comparing Hamilton to Madison. To quantify this, we:\n",
    "- Went through *each paper of Hamilton* and computed the *rate* that each of our marker words were used.\n",
    "- Went through *each paper of Madison* and computed the *rate* that each of our marker words were used.\n",
    "\n",
    "Then we told a \"classifer\" to \"train itself\" on the known papers. We essentially said:\n",
    "- Hello classifier, this paper *was written by Hamilton* and look! It has a lot of instances of the marker word \"while\" in it\n",
    "- Hello classifier, this paper *was written by Madison* and look! It has almost no instances of \"while\" but a lot of instances of \"whilst\"\n",
    "\n",
    "The classifer then \"teaches itself\" that papers which use the word \"while\" are probably written by Hamilton and papers which use the word \"whilst\" are probably written by Madison. Then we\n",
    "- Went through the *disputed papers* and computed the rates of the marker words\n",
    "- Fed these rates into the classifier algorithm\n",
    "- Learned that the classifier probably thought *Madison* was the author of the papers.\n",
    "\n",
    "Different classifiers work in different ways, but this is the high level overview of what was going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## This Time: Word Embeddings\n",
    "\n",
    "Now we will transition a bit to studying *the language itself*, instead of how different authors *use the language*. Probably *the most* useful concept in this area is that of a *word embedding*. It works as follows.\n",
    "\n",
    "Let $L$ be the *language* we are working with. This doesn't necessarily mean \"English, French, etc.\" It means \"all the words we currently care about.\" So for instance, we might pick $L$ to be:\n",
    "- The words in the English Language (hot, cold, blue, ...), PLUS\n",
    "- Common names (Thomas, Sarah, ...), PLUS\n",
    "- Important companies (Gamestop, Nokia, ...), PLUS\n",
    "- Important acronyms (FBI, CIA, ...), PLUS\n",
    "- ...\n",
    "\n",
    "Pick a positive integer $N$. A *word embedding of $L$* is simply a map \n",
    "$$\n",
    "L\\to \\mathbb{R}^N.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In discussing word embeddings, we will usually use the notion \n",
    "$$\n",
    "w\\to v_w,\n",
    "$$\n",
    "so \n",
    "$$\n",
    "car\\to v_{car}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Seems simple enough! But, there are a few important things that we want to *try* and achieve with the map:\n",
    "- \"Similar\" words should map to \"similar\" vectors\n",
    "    - Chair, couch, sofa, and stool should be mapped to \"close\" vectors in $\\mathbb{R}^N$\n",
    "- \"Dissimilar\" words should map to \"dissimilar\" vectors\n",
    "    - Be careful about \"dissimilar\" though! Up and down *are opposites*, but they are fairly similar words...\n",
    "- N should be \"big enough\" to allow all the vectors to \"spread out\" and encode similarities between different things\n",
    "- N should be \"small enough\" so that we can actually *compute* with these vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## What does \"similar\" mean?\n",
    "\n",
    "There are a few ways of measuring the \"similarity\" of two vectors. One that is common in machine learning is *cosine similarity*:\n",
    "$$\n",
    "sim(u,v) = \\frac{u\\cdot v}{|u||v|}.\n",
    "$$\n",
    "Explicitly, if $u = (u_1,\\dots,u_N)$ and $v = (v_1,\\dots,v_N)$, then \n",
    "$$\n",
    "sim(u,v) = \\frac{u_1v_1+\\dots+u_Nv_N}{\\sqrt{u_1^2+\\dots+u_N^2}\\sqrt{v_1^2+\\dots+v_N^2}}\n",
    "$$\n",
    "This makes for a decent participation check!\n",
    "\n",
    "## ****** Participation Check **********************************\n",
    "\n",
    "Write a function which takes in two \"vectors\" (consider them as lists of numbers) u and v, and returns sim(u,v)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def sim(u,v):\n",
    "    # Your code here\n",
    "    uv = sum([u[i]*v[i] for i in range(len(u))])\n",
    "    ul = sum([u[i]^2 for i in range(len(u))])^(1/2)\n",
    "    vl = sum([v[i]^2 for i in range(len(v))])^(1/2)\n",
    "    return(float(uv)/(ul*vl))\n",
    "\n",
    "\n",
    "u = [1,2,3]\n",
    "v = [-1,-2,-3]\n",
    "print(sim(u,v))\n",
    "\n",
    "u = [1,2,3]\n",
    "v = [2,4,6]\n",
    "print(sim(u,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ***************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Cosine similarity takes *no account* of the *size* of the vectors; it only measures *which direction the vectors are pointing*:\n",
    "\n",
    "![](cos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A \"Bad\" Word Embedding\n",
    "\n",
    "Let's order every word in $L$ alphabetically:\n",
    "\n",
    "![](words.png)\n",
    "\n",
    "We can define a \"one hot embedding\" by mapping the $i$th word in $L$ to the vector with a single $1$ in the $i$th index, and $0$ everywhere else:\n",
    "\n",
    "![](words2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unfortunately this leads to some issues!\n",
    "\n",
    "## ******** Participation Check ***********************\n",
    "\n",
    "Give *two reasons* why the one-hot embedding is not a great word embedding (hint: look back at what we *want* out of a word embedding. Then look at the definition of cosine similarity. Also, how big do you think these vectors are?)\n",
    "\n",
    "- Reason 1:\n",
    "- Reason 2:\n",
    "\n",
    "## ****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Better Word Vectors\n",
    "\n",
    "The current state of the art method for producing word vectors came out of work of several Googlers. The framework is known as *word2vec*, and you can see more here: https://en.wikipedia.org/wiki/Word2vec#CBOW_and_skip_grams\n",
    "\n",
    "The general idea: \"similar\" words are used in \"similar\" contexts. Just like humans! Maybe you have heard the old proverb\n",
    "\n",
    ">> Tell me your friends and I'll tell you who you are\n",
    "\n",
    "If you have a lot of religious friends, it is *more likely* that you are religious. If you have a lot of friends from Michigan, it is *more likely* that you spent some of your life in Michigan. Etc.\n",
    "\n",
    "Let's play a game! Think of a word that could complete this sentence. Type, *but do not send*, that word into the chat bar. We will try to all \"simultaneously\" send it so as to not influence anyone else.\n",
    "\n",
    "![](food.png)\n",
    "\n",
    "We all picked *somewhat* similar words! Certainly there was a lot of variation, but we all knew that the word we were looking for was:\n",
    "- Edible (you *ate it*)\n",
    "- A *specific type* of edible (\"spicy\")\n",
    "- *Probably* a plural or \"plural type\" word!\n",
    "\n",
    "From this we can learn that words like \"tacos\" or \"curry\" or \"chili\" are *somewhat similar*: they are \"edible spicy pluralish food words\"\n",
    "\n",
    "We can also learn that words like \"cars\" and \"blue\" and \"hockey\" are *somewhat different* to tacos, chili, and curry. Cars would *never* be used to fill in that sentence!\n",
    "\n",
    "This still seems somewhat lacking...but imagine how many sentences there are in the world! Imagine if I had provided you with this sentence instead:\n",
    "\n",
    "![](food2.png)\n",
    "\n",
    "We now know that we are looking for a dish *associated with India*! Could it be tacos? *Maybe*. Could it be kifto? *Maybe*. But *probably* it is a word like curry, vindaloo, rista, etc. We have thus separated the \"edible spicy pluralish *Indian* words\" from the \"edible spicy pluralish *non-Indian*\" words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implementing this idea\n",
    "\n",
    "I am not going to go over in detail how you can use this to get word vectors. But *basically* you:\n",
    "- Extract a *bunch* of sentences from somewhere\n",
    "    - Common sources: Wikipedia, database of news stories, ...\n",
    "- Tell your computer to read the sentences ~5 words at a time (a \"window\")\n",
    "- Have the computer \"keep track\" of which words appeared in similar windows\n",
    "\n",
    "After doing this for hours and hours and hours on millions and millions and millions of sentences, the computer becomes *amazingly smart*.\n",
    "\n",
    "The really cool thing is that we can access the results of their training! This involves first \"downloading\" a fairly large (~70 MB) file into CoCalc, so you may not be able to follow along right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50') #Uncomment if/when you want to come back and play with this, but you'll have a chance to do it on homework if you don't want to right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fc28203df10>"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'Thomas' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5e5bbee1ccdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Thomas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/ext/sage/sage-9.2/local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext/sage/sage-9.2/local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext/sage/sage-9.2/local/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'Thomas' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "glove_vectors['Thomas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10002 ,  0.58581 , -0.18892 , -0.78133 ,  0.56788 ,  0.77982 ,\n",
       "       -1.2221  ,  0.29163 , -0.34162 , -1.2892  , -0.44901 ,  1.1249  ,\n",
       "       -1.2433  , -0.99447 ,  0.28163 , -0.27078 ,  0.23618 , -1.1491  ,\n",
       "       -0.82672 , -0.4048  , -0.098151, -0.067551, -0.32379 ,  0.20813 ,\n",
       "       -0.048732, -1.6105  ,  0.084971, -0.83351 , -0.98128 ,  0.096412,\n",
       "        1.2549  , -0.90291 ,  0.42223 , -0.44529 ,  0.24018 , -0.6333  ,\n",
       "        0.26302 ,  0.49929 ,  0.7031  ,  0.11011 ,  0.94033 ,  0.82832 ,\n",
       "       -0.15095 , -0.11306 ,  0.099107,  0.90746 , -0.13653 , -0.89517 ,\n",
       "       -0.72975 ,  0.86626 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors['thomas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25522 , -0.75249 , -0.86655 ,  1.1197  ,  0.12887 ,  1.0121  ,\n",
       "       -0.57249 , -0.36224 ,  0.44341 , -0.12211 ,  0.073524,  0.21387 ,\n",
       "        0.96744 , -0.068611,  0.51452 , -0.053425, -0.21966 ,  0.23012 ,\n",
       "        1.043   , -0.77016 , -0.16753 , -1.0952  ,  0.24837 ,  0.20019 ,\n",
       "       -0.40866 , -0.48037 ,  0.10674 ,  0.5316  ,  1.111   , -0.19322 ,\n",
       "        1.4768  , -0.51783 , -0.79569 ,  1.7971  , -0.33392 , -0.14545 ,\n",
       "       -1.5454  ,  0.0135  ,  0.10684 , -0.30722 , -0.54572 ,  0.38938 ,\n",
       "        0.24659 , -0.85166 ,  0.54966 ,  0.82679 , -0.68081 , -0.77864 ,\n",
       "       -0.028242, -0.82872 ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors['banana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'numpy.ndarray'>"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(glove_vectors['banana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vectors['banana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bananas', 0.8152028322219849),\n",
       " ('coconut', 0.7872510552406311),\n",
       " ('pineapple', 0.757981538772583),\n",
       " ('mango', 0.7556401491165161),\n",
       " ('beet', 0.7212650179862976),\n",
       " ('fruit', 0.7181406617164612),\n",
       " ('sugar', 0.7180197834968567),\n",
       " ('growers', 0.7165752053260803),\n",
       " ('peanut', 0.7018108367919922),\n",
       " ('cranberry', 0.6957995295524597)]"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tomato', 0.8521810173988342),\n",
       " ('fruit', 0.8491664528846741),\n",
       " ('vegetables', 0.8399223685264587),\n",
       " ('delicious', 0.8329547643661499),\n",
       " ('fruits', 0.8324853777885437),\n",
       " ('roasted', 0.82856285572052),\n",
       " ('spices', 0.8251430988311768),\n",
       " ('savory', 0.8186075091362),\n",
       " ('vegetable', 0.8137245178222656),\n",
       " ('soup', 0.8083689212799072)]"
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(['edible','spicy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('down', 0.9523451924324036),\n",
       " ('out', 0.9315087795257568),\n",
       " ('while', 0.9285621047019958),\n",
       " ('back', 0.9047043919563293),\n",
       " ('off', 0.8998678922653198),\n",
       " ('put', 0.8958144187927246),\n",
       " ('just', 0.8927414417266846),\n",
       " ('away', 0.8920525908470154),\n",
       " ('over', 0.8814347386360168),\n",
       " ('to', 0.8726335763931274)]"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bean', 0.7645796537399292),\n",
       " ('ginger', 0.750214159488678),\n",
       " ('pepper', 0.7419105172157288),\n",
       " ('cook', 0.7234705090522766),\n",
       " ('fry', 0.719668447971344),\n",
       " ('chili', 0.7026278376579285),\n",
       " ('onions', 0.6911578178405762),\n",
       " ('berry', 0.6713414788246155),\n",
       " ('rice', 0.6642091870307922),\n",
       " ('lemon', 0.6562460660934448)]"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('curry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barack', 0.9674171805381775),\n",
       " ('bush', 0.9642481207847595),\n",
       " ('clinton', 0.9606046080589294),\n",
       " ('mccain', 0.912293553352356),\n",
       " ('dole', 0.8878743052482605),\n",
       " ('gore', 0.8848039507865906),\n",
       " ('hillary', 0.8776552081108093),\n",
       " ('rodham', 0.8401790857315063),\n",
       " ('kerry', 0.8261427879333496),\n",
       " ('biden', 0.8095825910568237)]"
      ]
     },
     "execution_count": 15,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fbi', 0.8427013158798218),\n",
       " ('intelligence', 0.7883837819099426),\n",
       " ('informant', 0.7376471757888794),\n",
       " ('operative', 0.7352996468544006),\n",
       " ('covert', 0.7318969964981079),\n",
       " ('agents', 0.7244440913200378),\n",
       " ('pentagon', 0.7093384265899658),\n",
       " ('investigation', 0.6950873136520386),\n",
       " ('spy', 0.6949564218521118),\n",
       " ('investigators', 0.6905346512794495)]"
      ]
     },
     "execution_count": 16,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('cia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ucsf', 0.7638055682182312),\n",
       " ('sdsu', 0.7081701755523682),\n",
       " ('ucsc', 0.6888858675956726),\n",
       " ('u.c.', 0.6857913732528687),\n",
       " ('tardelli', 0.6850271224975586),\n",
       " ('ucsb', 0.6842514872550964),\n",
       " ('concordia', 0.6812412738800049),\n",
       " ('fgv', 0.6811478734016418),\n",
       " ('eai', 0.671143651008606),\n",
       " ('uc', 0.6686808466911316)]"
      ]
     },
     "execution_count": 17,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('ucsd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's do some crazy stuff now. Analogies! For students that didn't go through elementary school/middle school in the US, there is a common type of \"test\" that involves *analogies*:\n",
    "\n",
    "- Word1 is to Word2 as Word3 is to __________\n",
    "\n",
    "I think it is easiest to just give examples:\n",
    "\n",
    "- MAN is to KING as WOMAN is to _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523603677749634),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473883032798767),\n",
       " ('elizabeth', 0.7460220456123352),\n",
       " ('princess', 0.7424569725990295),\n",
       " ('kingdom', 0.7337411642074585),\n",
       " ('monarch', 0.7214490175247192),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099430561065674)]"
      ]
     },
     "execution_count": 18,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['king','woman'], negative = ['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What happened here? You start with KING, and you want to \"replace\" the \"manliness\" of KING with \"womanliness.\" But we have *vectors*; we can literally do this!\n",
    "\n",
    "$$\n",
    "v_{king} - v_{man} + v_{woman}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41736597,  0.90427005, -1.0050299 , -0.06202102,  0.49725997,\n",
       "        0.80667007, -0.14855   ,  0.80365   , -0.15653998, -0.66973996,\n",
       "        0.23435399,  0.62476   ,  0.925871  , -0.97099996,  0.92566   ,\n",
       "        0.89915   , -1.54596   , -0.52625   ,  0.13695401,  0.66199005,\n",
       "        0.4871601 ,  0.37035   , -0.214214  ,  0.10100996,  0.71358   ,\n",
       "       -2.0874999 , -1.1362001 , -1.1496099 , -0.53599   ,  0.27389997,\n",
       "        1.6723    ,  0.02930999, -0.77656007,  0.46056286,  0.34866   ,\n",
       "       -0.05741701,  0.19444   , -0.207748  , -0.73038995, -0.10751998,\n",
       "        0.235544  ,  0.96423995, -0.46993998, -0.48727497, -0.25399995,\n",
       "        0.4621299 , -0.66081   , -1.9451499 , -0.68797004, -0.49784005],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors['king'] - glove_vectors['man'] + glove_vectors['woman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "How good is this?\n",
    "\n",
    "AMERICA is to AMERICAN as CHINA is to ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chinese', 0.8827552199363708),\n",
       " ('taiwan', 0.8043252825737),\n",
       " ('korean', 0.8006567358970642),\n",
       " ('japanese', 0.7709087133407593),\n",
       " ('beijing', 0.7643234729766846),\n",
       " ('taiwanese', 0.7553259134292603),\n",
       " ('japan', 0.7499627470970154),\n",
       " ('asian', 0.7480012774467468),\n",
       " ('korea', 0.7438861131668091),\n",
       " ('mainland', 0.7313058376312256)]"
      ]
     },
     "execution_count": 20,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['american','china'], negative = ['america'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OBAMA is to AMERICAN as PUTIN is to _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('russian', 0.8495172262191772),\n",
       " ('soviet', 0.7639276385307312),\n",
       " ('ukrainian', 0.7484616041183472),\n",
       " ('french', 0.7267457246780396),\n",
       " ('polish', 0.7154698967933655),\n",
       " ('german', 0.7137736082077026),\n",
       " ('russia', 0.7072685360908508),\n",
       " ('dutch', 0.6925777196884155),\n",
       " ('canadian', 0.6919834613800049),\n",
       " ('cuban', 0.6899456977844238)]"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['american','putin'], negative = ['obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "BLUEBERRY is to BLUE as RASPBERRY is to ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('red', 0.7710092067718506),\n",
       " ('purple', 0.7424114942550659),\n",
       " ('yellow', 0.7413184642791748),\n",
       " ('black', 0.7351616024971008),\n",
       " ('orange', 0.7255880236625671),\n",
       " ('golden', 0.7171742916107178),\n",
       " ('colored', 0.7114768624305725),\n",
       " ('pink', 0.7066935896873474),\n",
       " ('crimson', 0.7029789090156555),\n",
       " ('stripes', 0.7023863196372986)]"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['blue','raspberry'], negative = ['blueberry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Of course it is not perfect...\n",
    "\n",
    "UP is to DOWN as LEFT is to ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('broke', 0.8590975403785706),\n",
       " ('leaving', 0.8382939100265503),\n",
       " ('back', 0.8342666625976562),\n",
       " ('after', 0.8274049758911133),\n",
       " ('when', 0.8219099640846252),\n",
       " ('off', 0.8120282292366028),\n",
       " ('pulled', 0.8114712238311768),\n",
       " ('before', 0.8065346479415894),\n",
       " ('broken', 0.802820086479187),\n",
       " ('then', 0.7916644811630249)]"
      ]
     },
     "execution_count": 23,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['down','left'], negative = ['up'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But I still think it's pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oooooooooooooooooo', 0.9367011785507202),\n",
       " ('x.xx.xx.xx.x', 0.9230756759643555),\n",
       " ('ooooooooooooooo', 0.9122284650802612),\n",
       " ('oooooooooooooooooooo', 0.8784708976745605),\n",
       " ('oo.oo', 0.8721545934677124),\n",
       " ('oooooooooooooo', 0.8281261920928955),\n",
       " ('ooooo', 0.7913150191307068),\n",
       " ('oooooo', 0.7676581740379333),\n",
       " ('oooooooo', 0.7541344165802002),\n",
       " ('oooo', 0.7352308630943298)]"
      ]
     },
     "execution_count": 24,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar(positive = ['oooooooooo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plots Plots Plots Plots Plots Plots (EVERYBODYYYYYYYYY)\n",
    "\n",
    "Let's try some visualization (be careful; we are projecting from 50 dimensions to 2 dimensions, so this is a bit science fiction, but not too much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "def reduce_to_2_dim(M):\n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "    \n",
    "    svd = TruncatedSVD(n_components = 2, n_iter = n_iters, random_state = 42)\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    print(\"Done.\")\n",
    "    return M_reduced\n",
    "\n",
    "def plot_embeddings(M_reduced,word2Ind, words):\n",
    "    b = np.array([word2Ind[word] for word in words])\n",
    "    x = M_reduced[b,0]\n",
    "    y = M_reduced[b,1]\n",
    "    plt.scatter(x,y)\n",
    "    for i in range(len(words)):\n",
    "        plt.annotate(words[i],(x[i],y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 10 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = ['boy','girl','father','mother','son','daughter','aunt','uncle','niece','nephew']\n",
    "word2Ind = {ws[i]:i for i in range(len(ws))}\n",
    "vs = np.asarray([glove_vectors[w] for w in ws])\n",
    "M = reduce_to_2_dim(vs)\n",
    "plot_embeddings(M,word2Ind,ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note how there is a *linear trend* from the \"male to female\" version of each word. This is what makes the analogies possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 6 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = ['america','american','france','french','spain','spanish']\n",
    "word2Ind = {ws[i]:i for i in range(len(ws))}\n",
    "vs = np.asarray([glove_vectors[w] for w in ws])\n",
    "M = reduce_to_2_dim(vs)\n",
    "plot_embeddings(M,word2Ind,ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sagemath",
   "metadata": {
    "cocalc": {
     "description": "Open-source mathematical software system",
     "priority": 10,
     "url": "https://www.sagemath.org/"
    }
   },
   "name": "sage-9.2",
   "resource_dir": "/ext/jupyter/kernels/sage-9.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}