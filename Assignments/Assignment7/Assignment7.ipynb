{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Math 157: Intro to Mathematical Software\n",
    "### UC San Diego, Winter 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Homework 7: due Thursday, Feb 25 at 8PM Pacific\n",
    "\n",
    "### Kernel: \n",
    "All computations in this notebook should use the Python3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Collaborators/resources used:\n",
    "To start, please list all students you worked with in the box below. Additionally, include basic citations to resources you used along the way (it can be as simple as Title: hyperlink_to_the_webpage). You do not need to add citations to hyperlinks of resources that I have already added.\n",
    "\n",
    "Remember! Collaboration is *encouraged*, but *you must write up answers in your own words*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "References/collaborators here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem 1: Pandas Syntax (Lectures 18, 19)\n",
    "\n",
    "The purpose of this problem is to reinforce pandas syntax. We will use the `pokemon.csv` file that was introduced in Lecture 18. Start by reading in the `pokemon.csv` file into a pandas dataframe called `pokemon`, as in Lecture 18 (be sure to add in the `index_col` hyperparameter as in lecture!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "pokemon = #Replace this comment with your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a.)\n",
    "\n",
    "How many pokemon in the dataframe *have only one type*? Namely, how many pokemon *have a Type 1*, but *have no entry for a Type 2*? (There are multiple ways of finding this out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b.)\n",
    "\n",
    "Extract a dataframe `attackingWater` consisting of pokemon which \n",
    "- Either have `Type 1` or `Type 2` equal to `'Water'`, *and*\n",
    "- Have a base `Attack` stat *strictly greater than* `110`.\n",
    "\n",
    "Execute `attackingWater.head()` to display the first 5 pokemon of this new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "attackingWater.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c.) \n",
    "\n",
    "Which value of `Type 1` has the *quickest* pokemon on average? I.e. if you group pokemon by *their first type*, which group has the highest average speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d.) \n",
    "\n",
    "Change your `pokemon` dataframe so that any pokemon from Generation 1 is automatically considered Legendary. After making this change, print out the new row corresponding to `Pikachu` and to `Donphan` to verify the change happened correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here (be sure to add in the print statements for Pikachu and Donphan!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem 2: Pipelines and Data Processing (Lectures 18, 19)\n",
    "\n",
    "The purpose of this problem is to study the yearly \"bonuses\" paid out to employees in a hypothetical company. The file `bonuses.csv` contains data for this company's employees; I have read it into a pandas DataFrame below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('bonuses.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a.) There are 75 missing salaries in the dataframe. Impute these values by replacing the null entries with the *mean salary* in this company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b.) Create and add a new `NumPerformanceReview` column to the dataframe. This new column should turn the *categorical data* in the `PerformanceReview` column into *numeric data* by using Scikit Learn's *ordinal encoder* (which has already been imported for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c.) Create and add a new column `SalaryOvertime` consisting of an *interaction term* between the `Salary` and `OvertimeWorked` column. Namely, the ith entry in `SalaryOvertime` should simply be the *product* of the ith entries in `Salary` and `OvertimeWorked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d.) Run a regression to fit a linear model of the form\n",
    "$$\n",
    "bonus = \\beta_0 + \\beta_1*salary + \\beta_2*NumPerformanceReview + \\beta_3*OvertimeWorked + \\beta_4*SalaryOvertime.\n",
    "$$\n",
    "Write the coefficients in the markdown cell below the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Answer here:\n",
    "\n",
    "- $\\beta_0 = $\n",
    "- $\\beta_1 = $\n",
    "- $\\beta_2 = $\n",
    "- $\\beta_3 = $\n",
    "- $\\beta_4 = $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem 3: Bias Variance Tradeoff and Overengineering (Lecture 19, Participation Check 2)\n",
    "\n",
    "The file `hypotheticalData.csv` contains a made up data set. There are 20 rows in the data set; each row is simply a (x,y) pair. The purpose of this question is to test how well various regressions can \"predict\" this data set, and to introduce the \"bias-variance\" tradeoff. Below are import statements which could be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data has been read into a pandas DataFrame below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df = pd.read_csv('hypotheticalData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a.)\n",
    "\n",
    "Make and display a scatter plot of the data set. Then create a *training data set* and a *testing data set*. The training data set should consist of the *first 15 rows* of `df`, and the *testing data set* should consist of the *last 5 rows* of `df` (don't use Scikit Learn's train test split function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b.) Using Scikit Learn, create a *linear regression* on the *training data set*. The *explanatory variable* should be x, and the *explained variable* should be y. Using Scikit Learn's `mean_squared_error` function, measure the total mean squared error of the model on *both the training set and the testing set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:\n",
    "- training error:\n",
    "- testing error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c.) Create two new data sets, `quadraticTrain` and `quadraticTest`, which equal your training and testing dataframes respectively, but with an *added column* equal to the *square* of the x-variable. Repeat part b.) for this new data set; explicitly, train a linear model on `quadraticTrain`, where you predict $y$ based on $x$ and the new $x^2$ column, and then compute the mean squared error of this model on both `quadraticTrain` and `quadraticTest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:\n",
    "- training error:\n",
    "- testing error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d.) Finally, create two new data sets `overengineeredTrain` and `overengineeredTest` which equal your original training and testing dataframes, but with *many new columns* equal to `x**2, x**3, ..., x**12`. Repeat part b.) on this new data set; explicitly, train a linear model on `overengineeredTrain,` where you predict $y$ based on $x, x^2,\\dots,x^{12}$, and then compute the mean squared error of this model on both `overengineeredTrain` and `overengineeredTest`. \n",
    "\n",
    "(Hints: You can use a for loop to add many columns to a dataframe. To regress on a lot of columns of a DataFrame, it may be helpful to use iloc. But you can also just handcode it in; either works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:\n",
    "- training error:\n",
    "- testing error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "e.) Which of the three models you calculated would you \"trust\" most to make predictions on a new (previously unseen) data point? I.e. if someone gave you a \"random\" x value which you hadn't seen before, but which fit into the context of the original data set, which model would you use to predict the corresponding y value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem 4: Hypothesis Testing, or, Are NBA Players *Really* Really Tall? (Lecture 19)\n",
    "\n",
    "The National Basketball Association is America's professional basketball league. A common saying is that you \"have to\" be very tall to play professional basketball, although there are some notable exceptions (Muggsy Bogues was the shortest player to ever play in the league at 160 cm tall (5 ft 3 inches) and Spud Webb *won the freaking slam dunk competition in 1986 at only 170 cm tall (5 ft 7 inches)*; the runner up, Dominique Wilkins, was *33 cm (13 inches) taller* than Spud).\n",
    "\n",
    "In the directory of this assignment there are three csv files, `NBA97.csv`, `NBA18.csv`, and `normal.csv`. The data sets contain information on the heights of\n",
    "- the NBA players from the 1997-1998 season\n",
    "- the NBA players from the 2018-2019 season\n",
    "- \"normal\" humans\n",
    "\n",
    "\n",
    "All heights are measured in centimeters. In the NBA files, the rows contain info on player names. In the average human file, each human is just assigned a random number.\n",
    "\n",
    "These files have been read into various DataFrames below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "nba97 = pd.read_csv('NBA97.csv')\n",
    "nba18 = pd.read_csv('NBA18.csv')\n",
    "norm = pd.read_csv('normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "nba97.loc[nba97['player_name'] == 'Michael Jordan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "nba18.loc[nba18['player_name'] == 'Kevin Durant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a.) \n",
    "\n",
    "The first two parts of this problem will determine if NBA players have \"gotten taller\" over time. Since there are more players in the 2018-2019 season than there were in the 1997-1998 season, we will need to first take a random sample of the players in NBA18. Create a dataframe `random18` consisting of a random sample of 441 players from the 2018-2019 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "random18 = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, create a histogram which simultaneously displays the heights in `nba97` and in `random18`, as in the frog example of Lecture 19. I have already set up the correct 'bins'; you will simply need to finish the pyplot syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "bins = numpy.linspace(160, 240, 15)\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b.) \n",
    "\n",
    "Using scipy.stats, perform a t-test comparing the heights in `nba97` and `random18`. What $p$ value do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import scipy.stats\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c.) \n",
    "\n",
    "The final two parts of this problem will compare NBA players to the general population. We will choose to compare `nba18` to `norm` (a similar story would be told if you used `nba97`).\n",
    "\n",
    "As in part a.), the number of entries in these frames is not the same. Create a random sample of 530 entries from norm and put it into a `randomNorm` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "randomNorm = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, create a histogram which simultaneously displays the heights in `nba18` and in `randomNorm`, as in the frog example of Lecture 19. I have already set up the correct 'bins'; you will simply need to finish the pyplot syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "bins = numpy.linspace(140, 240, 20)\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d.)\n",
    "\n",
    "Using scipy.stats, perform a t-test comparing the heights in `nba18` and `randomNorm`. What $p$ value do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import scipy.stats\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem 5: Simpson's Paradox (Lecture NaN; just use your thinking)\n",
    "\n",
    "Simpson's paradox is very cool.\n",
    "\n",
    "a.)\n",
    "\n",
    "This example is (essentially) taken from this research article: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1339981/\n",
    "\n",
    "A drug company is testing two treatments for kidney stones to see which treatment is most effective. The drug company tests each treatment on 350 individuals. After the experimentation, the company noticed that the drug had different effects on people with *large kidney stones* compared to people with *small kidney stones*. The success rate of each treatment is summarized below:\n",
    "\n",
    "\\;\\; | Treatment A     | Treatment B |\n",
    "------| ----------- | ----------- |\n",
    "Small Stones| 81 cured out of 87    |    234 cured out of 270 |\n",
    "Large Stones| 192 cured out of 263  | 55 cured out of 80      |\n",
    "\n",
    "\n",
    "Compute the success rate (as a percentage) for the different treatments on: Large Stones, Small Stones, and Kidney Stones in general. Enter your answers into the partially filled markdown cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#code here if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Answer here:\n",
    "\n",
    "\\;\\; | Treatment A     | Treatment B |\n",
    "------| ----------- | ----------- |\n",
    "Small Stone Success Rate| XX%|XX%\n",
    "Large Stone Success Rate| XX%|XX%\n",
    "Total Success Rate| XX%|XX%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b.) \n",
    "\n",
    "If you were a doctor, which treatment plan would you recommend to a patient that had kidney stones? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c.) \n",
    "\n",
    "There is a different form of Simpson's paradox displayed with the following made up example.\n",
    "\n",
    "Consider the data sets `data1`, `data2`, and `data` defined below. The points in `data` have been plotted for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "data1 = [(1,6),(1.2,6.3),(3,8)]\n",
    "data2 = [(6,.1),(6.8,.4),(8,2)]\n",
    "data = data1+data2\n",
    "pyplot.scatter([i[0] for i in data], [i[1] for i in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Suppose you ran three linear regressions to predict y based on the explanatory variable x: one based on `data1`, one based on `data2`, and one based on `data`. Which models would result in lines with a *positive* slope? (You do not have to actually compute the regressions unless you want to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d.) \n",
    "\n",
    "Spend at least two minutes thinking about the following question. Once you have done that, put \"Yes\" into the markdown cell below. You do not have to add any other \"answer\" other than saying \"Yes\" (seriously!); this is purely \"food for thought\"\n",
    "\n",
    "In the example data set from part c.), is x positively or negatively correlated with y? In other words, if someone told you that x was *increasing*, would you expect y to *increase as well* or would you expect y to *decrease*? Can you think of a real world example of a phenomenon like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Did you spend two minutes thinking about this question: __________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}